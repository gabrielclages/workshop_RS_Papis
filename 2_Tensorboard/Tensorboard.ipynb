{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems: Tensorboard\n",
    "\n",
    "The computations you'll use TensorFlow for - like training a massive deep neural network - can be complex and confusing. To make it easier to understand, debug, and optimize TensorFlow programs, Tensorflow included a suite of visualization tools called TensorBoard. You can use TensorBoard to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data like images that pass through it. When TensorBoard is fully configured, it looks like this:\n",
    "\n",
    "<img src=\"http://edwardlib.org/images/tensorboard-distributions.png\"  width=\"600\">\n",
    "\n",
    "\n",
    "TensorBoard operates by reading TensorFlow events files, which contain summary data that you can generate when running TensorFlow. Here's the general lifecycle for summary data within TensorBoard.\n",
    "\n",
    "First, create the TensorFlow graph that you'd like to collect summary data from, and decide which nodes you would like to annotate with summary operations.\n",
    "\n",
    "For example, suppose you are training a convolutional neural network for recognizing MNIST digits. You'd like to record how the learning rate varies over time, and how the objective function is changing. Collect these by attaching tf.summary.scalar ops to the nodes that output the learning rate and loss respectively. Then, give each scalar_summary a meaningful tag, like 'learning rate' or 'loss function'.\n",
    "\n",
    "Perhaps you'd also like to visualize the distributions of activations coming off a particular layer, or the distribution of gradients or weights. Collect this data by attaching tf.summary.histogram ops to the gradient outputs and to the variable that holds your weights, respectively.\n",
    "\n",
    "Operations in TensorFlow don't do anything until you run them, or an op that depends on their output. And the summary nodes that we've just created are peripheral to your graph: none of the ops you are currently running depend on them. So, to generate summaries, we need to run all of these summary nodes. Managing them by hand would be tedious, so use tf.summary.merge_all to combine them into a single op that generates all the summary data.\n",
    "\n",
    "Then, you can just run the merged summary op, which will generate a serialized Summary protobuf object with all of your summary data at a given step. Finally, to write this summary data to disk, pass the summary protobuf to a tf.summary.FileWriter.\n",
    "\n",
    "The FileWriter takes a logdir in its constructor - this logdir is quite important, it's the directory where all of the events will be written out. Also, the FileWriter can optionally take a Graph in its constructor. If it receives a Graph object, then TensorBoard will visualize your graph along with tensor shape information. This will give you a much better sense of what flows through the graph: see Tensor shape information.\n",
    "\n",
    "In the previous section, we made use of the tf.Estimator API to create our model. One of the many advantages of using the Estimator API is that the summary log will be written to model_dir of the estimator. For this part of the tutorial we will expand on the previous model.\n",
    "\n",
    "\n",
    "#### GOALS: \n",
    "\n",
    "In this tutorial we will learn about:\n",
    "- Using Tensorboard to debug model\n",
    "- Looking at Tensorboard scalars to help you improve upon your model\n",
    "\n",
    "\n",
    "This tutorial will be fully run from the command line since that is the best way to deploy the jobs when using Floyd Hub.\n",
    "\n",
    "#### Let's get started:\n",
    "\n",
    "Step 1: `cd 2_Tensorboard`\n",
    "\n",
    "Step 2: `floyd login` (enter your username and password)\n",
    "\n",
    "Step 3: `floyd init humancoders/recsys`\n",
    "\n",
    "Step 4: `floyd run --tensorboard \"python wide_deep.py\"`\n",
    "\n",
    "wide_deep.py is a very similar model to the one we built in the last session. The only difference is that we are now using it in a python format as opposed to a Jupyter notebook.\n",
    "\n",
    "<img src=\"images/floyd_hub.png\"  width=\"600\">\n",
    "\n",
    "Step 5: `Open Link seen in terminal. In my case this is: https://www.floydhub.com/humancoders/projects/recsys/22\"`\n",
    "\n",
    "Step 6: `Click on the link`\n",
    "\n",
    "<img src=\"images/link.png\"  width=\"600\">\n",
    "\n",
    "Step 7: Now, that you can deploy the model, let's look at the parser for things you can change in the model and try different combinations of models, <a href=\"https://www.tensorflow.org/api_docs/python/tf/train/Optimizer\" style=\"color: #6D00FF;\">optimizers</a>, hidden units and learning rates. You can try ANYTHING to change anything to decrease the loss and increase accuracy.\n",
    "\n",
    "<img src=\"images/parser.png\" width=\"600\">\n",
    "\n",
    "Note that by default it will run the wide model. Feel free to spend the next 30 minutes playing with the model and see if you can lower the cross-validation loss. If you would like to change the learning_rate for example, you can run `floyd run --tensorboard \"python wide_deep.py --learning_rate 0.00001\"`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits/Source\n",
    "\n",
    "[0] https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
